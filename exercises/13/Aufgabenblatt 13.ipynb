{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e43ae6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab5eeaf",
   "metadata": {},
   "source": [
    "# Aufgabe 1 Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00536a0-af5b-495f-95a8-77be0c0bbc53",
   "metadata": {},
   "source": [
    "<p style=\"border-left:5px solid red;padding:0.6em;box-sizing:border-box;\">\n",
    "<strong>Lernziele:</strong><br/>\n",
    "   In dieser Übung werden wir uns mit einer Methode zur bestimmung von optimalen Hyperparamtern beschäftigen. In Aufgabe 2 und 3 werden wir uns neuronale Netzwerke vertieft anschauen. </p>\n",
    "\n",
    "<p style=\"border-left:5px solid blue;padding:0.6em;box-sizing:border-box;\">\n",
    "<strong>Wichtigste neuen Funktionen für diese Übung:</strong><br/>\n",
    "    Dies sind die wichtigsten Funktionen die sie während dieser Übung benötigen:<br>\n",
    "    Die jeweilige Syntax beschreibt eine examplarische Verwendung. Der Funktionsname ist jeweils ein Link zur offiziellen Dokumentation, welche alle Argumente der Funktion darlegt und ihre Funktionalität beschreibt. <br>\n",
    "    <b>Funktionen zur statistischen Analyse: </b><br>\n",
    "    <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\">GridSearchCV(...)</a><br>\n",
    "    <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\">Pipeline(...)</a><br>\n",
    "    <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\">LinearRegression(...)</a><br>\n",
    "    <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html\">PolynomialFeatures(...)</a><br>\n",
    "    <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\">train_test_split(...)</a><br>\n",
    "    <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\">MLPClassifier(...)</a><br>\n",
    "    <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\">accuracy_score(...)</a><br>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3717ab07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31134ad",
   "metadata": {},
   "source": [
    "In der ersten Aufgabe werden wir mit linearer Regression ein Polynom an einen Datensatz fitten. Dabei verwenden wir Gridsearch, um die optimalen Hyperparameter für diese verwendete Modellklasse zu finden, mit denen die Daten weder unterfittet noch überfittet werden. In diesem Fall ist die Modellklasse die Menge aller Polynome beliebigen Grades und der einzige Hyperparameter ist der Grad des Polynoms. Der Gridsearch-Algorithmus fittet die Daten für verschiedene Hyperparameter in einem vorgegebenen Bereich und bestimmt mithilfe von cross validation den besten Fit und damit die besten Hyperparameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7c33bf",
   "metadata": {},
   "source": [
    "## a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d667317d",
   "metadata": {},
   "source": [
    "Verwenden Sie pandas, um das Dataset `Data_1/data.csv` in einem Dataframe `df` zu laden. Der Datensatz besteht aus zwei Spalten `x` und `y`, wobei `y(x)` ein Polynom ist. Erstellen Sie zwei Dataframes `X` und `y`, die diese beiden Spalten enthalten. Beachten Sie, dass `X` für die Weiterverarbeitung ein 2D-Array sein muss, auch wenn dieses hier nur eine Spalte enthält (Sie können `np.reshape` verwenden, um das Array in die richtige Form zu bringen).\n",
    "\n",
    "Schauen Sie sich die Daten zuerst an, indem Sie sie plotten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa4d262",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db1d2160",
   "metadata": {},
   "source": [
    "##  b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750f1ae4",
   "metadata": {},
   "source": [
    "Um das Gridsearch durchzuführen, definieren wir eine Pipeline, welche die Schritte für den ganzen Ablauf des Fittens mit einem fixen Satz Hyperparameter enthält:\n",
    "\n",
    "```python\n",
    "polynom = Pipeline([(\"transf\", PolynomialFeatures()), (\"lr\", LinearRegression())])\n",
    "```\n",
    "\n",
    "Der erste Schritt, `PolynomialFeatures`, wandelt den Input `x` in ein Polynoml n-ten Grades um. Dieses wird anschliessend im zweiten Schritt mit linearer Regression gefittet.\n",
    "\n",
    "Als nächstes müssen wir einen Bereich von Hyperparametern definieren, über den wir iterieren wollen. Der relevante Hyperparameter, nämlich der Grad des Polynoms, wird durch das Argument `degree` bestimmt, das an `PolynomialFeatures` übergeben wird. Wir teilen dies dem Gridsearch-Algorithmus mit, indem wir ein <a href='https://docs.python.org/3/tutorial/datastructures.html#dictionaries'>Dictionary</a> `params` mit einem Eintrag `'transf__degree'` definieren. Der String setzt sich aus dem Namen des Schritts in der Pipeline und dem Namen des Arguments, das wir variieren möchten, zusammen.\n",
    "\n",
    "```python\n",
    "params = {'transf_degree': <Liste von Hyperparametern>}\n",
    "```\n",
    "\n",
    "Nun können wir das Gridsearch-Modell `GridSearchCV` erstellen (<a href='https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html'>Dokumentation</a>). Die relevanten Argumente sind `estimator` (die Fit-Pipeline), `param_grid` (das Dictionary mit den Hyperparameter-Bereichen) und `cv` (Anzahl cross-validation Aufteilungen).\n",
    "\n",
    "Wie Sie es aus Übung 11 kennen, können Sie mit der Funktion `fit()` den Fit ausführen. Anschliessend definieren Sie ein Array von x-Werten zwischen 0 und 1, auf denen Sie das Resultat mit `predict` verifizieren können. Achten Sie darauf, dass `predict()` ein 2D-Array erwartet (hier mit einer Spalte; verwenden Sie `np.reshape`). Plotten Sie die Datenpunkte zusammen mit den Voraussagen, um zu überprüfen, ob das Modell stimmt.\n",
    "\n",
    "Inspizieren Sie auch die Resultate des Gridsearch-Crossvalidierungsverfahrens: Die besten Hyperparameter sind im Attribut `best_params_` gespeichert. Die volle Information über die Scores der Fits mit verschiedenen Parametern finden Sie in `cv_results_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b730a81d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b42b11a6",
   "metadata": {},
   "source": [
    "## c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26a94fb",
   "metadata": {},
   "source": [
    "Verwenden Sie das Fitresultat, um die `y`-Werte für alle `x`-Werte aus der Datei `Data_1/X_final.csv` vorherzusagen. Stellen Sie die Voraussagen grafisch dar und vergleichen Sie mit dem Plot aus b)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f051f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "295a0ef1",
   "metadata": {},
   "source": [
    "# Aufgabe 2 Neuronale Netze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ec1929",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255ccea6",
   "metadata": {},
   "source": [
    "In der zweiten Aufgabe implementieren wir ein Programm, das neuronale Netze verwendet, um Punkten auf den beiden \n",
    "Armen einer Doppelspirale zu unterscheiden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6d4cf0",
   "metadata": {},
   "source": [
    "## a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512df823",
   "metadata": {},
   "source": [
    "Laden Sie zuerst die Datei `Data_2/data.csv` in ein Dataframe. Jede Zeile der Tabelle bezeichnet einen Punkt, wobei die ersten beiden Spalten die Koordinaten des Punktes sind und die letzte Spalte `y` angibt, auf welchem Arm der Spirale der Punkt liegt.\n",
    "\n",
    "Erstellen Sie zwei Dataframes `X` und `y`. Dabei soll `y` nur die Zuordnung der Punkte zu Spiralarmen enthalten und `X` die beiden andern Spalten.\n",
    "\n",
    "Stellen Sie die Werte grafisch dar, indem Sie `X` Werte als Koordinaten in einem Scatterplot plotten (`ax.scatter`). Verwenden Sie dabei die `y`, um die Farbe der Punkte zu bestimmen. Das Ziel des Netzwerkes ist es, die Punkte richtig den beiden Spiralen bzw. Farben zuzuweisen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0391c6ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "815bfe54",
   "metadata": {},
   "source": [
    "## b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655debc7",
   "metadata": {},
   "source": [
    "Teilen Sie `(X, y)` in einen Trainingsdatensatz `(X_train, y_train)` und einen Testdatensatz `(X_test, y_test)` auf. Benutzen Sie `MLPClassifier` (<a href='https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier'>Dokumentation</a>) um ein neuronales Netzwerk zu erstellen, und trainieren Sie es dann mit dem Trainingsdatensatz. Die relevanten Argumente sind:\n",
    "\n",
    "- max_iter\n",
    "- hidden_layer_sizes\n",
    "- random_state (int): Falls Sie den Zufallsgenerator immer gleich initialisieren wollen, um reproduzierbare Resultate zu erhalten.\n",
    "\n",
    "Limitieren Sie die Anzahl der Iterationen auf 5000, und probieren Sie verschiedene Anzahl hidden layers mit verschiedenen Anzahlen von Neuronen aus, um das beste Resultat zu erhalten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff85dfb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3fdcd00c",
   "metadata": {},
   "source": [
    "## c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbdfc7d",
   "metadata": {},
   "source": [
    "Verwenden Sie das resultierende neuronale Netz, um die Punkte in `X_test` zu klassifizieren und bewerten Sie die Genauigkeit der getroffenen Vorhersagen gegenüber `y_test` mit der Funktion `accuracy_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e79aea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09518b1b",
   "metadata": {},
   "source": [
    "## d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13671a2c",
   "metadata": {},
   "source": [
    "Verwenden Sie Pandas, um den Datensatz `X_final.csv` in einem Dataframe `df` zu laden.\n",
    "\n",
    "Der Datensatz enthält nun die Koordinaten der Punkte ohne ihre Zuordnung. Verwenden Sie das trainierte Netzwerk, um die Punkte den Spiralarmen zuzuordnen, und plotten Sie das Resultat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6525105",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45b0e021",
   "metadata": {},
   "source": [
    "# Aufgabe 3: Propagation durch ein neuronales Netz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9587a2b",
   "metadata": {},
   "source": [
    "In der letzten Aufgabe sollen Sie die Propagation durch die hidden Layers eines neuronalen Netzes selber implementieren. In jedem Layer nimmt jedes der $M$ Neuronen die $N$ Inputs, multipliziert jeden davon mit einem Gewicht und bildet dann die Summe. Dies entspricht einer linearen Abbildung eines $N$-Dimensionalen Inputvektors auf $M$ Neuronen, was wiederum als Multiplikation des Inputvektors mit einer $(M\\times N)$-Matrix aufgefasst werden kann. In jedem Neuron wird dann zu der Summe noch ein Offset oder Bias addiert und dann wird eine nichtlineare Aktivierungsfunktion darauf angewendet. Diese $M$ Zahlen sind der Output dieses Layers, der als Input an das nächste Layer übergeben wird. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42942d2e",
   "metadata": {},
   "source": [
    "## a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2957cf56",
   "metadata": {},
   "source": [
    "Schreiben Sie zuerst zwei Funktionen, die ein einzelnes hidden Layer mit einer ReLU- bzw. einer Sigmoid-Aktivierungsfunktion implementieren. Die Argumente der Funktion sind:\n",
    "\n",
    "- $N$-dimensionaler Inputvektor (1D-Array mit N Einträgen)\n",
    "- $(M\\times N)$-Gewichtsmatrix ($N$ Gewichte für jedes der $M$ Neuronen)\n",
    "- $M$-dimensionaler Biasvektor (ein Biaswert für jedes der $M$ Neuronen)\n",
    "\n",
    "Der Rückgabewert ist ein $M$-dimensionaler Vektor mit den Outputs aller Neuronen.\n",
    "\n",
    "Für die Matrixmultiplikation  können Sie `np.dot` oder `@` verwenden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2345aefd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35181910",
   "metadata": {},
   "source": [
    "## b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e542e6bd",
   "metadata": {},
   "source": [
    "Nutzen Sie das im nächsten Abschnitt gegebene Testarray zusammen mit der gegebenen Gewichtsmatrix und des Biasvektors um ihre Funktionen zu überprüfen. Vergleichen Sie Ihre ergebnisse mit den Resultaten, die wir Ihnen zur Verfügung stellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ee6cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "testarray = np.arange(1, 5)\n",
    "\n",
    "weight = np.ones((3, 4))\n",
    "bias = np.array([0, -10, -12])\n",
    "\n",
    "result_ReLU = np.array([10, 0, 0])\n",
    "result_sigmoid = np.array([0.9999546, 0.5, 0.11920292])\n",
    "\n",
    "# Ihr Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95862ca9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fcf5ae42",
   "metadata": {},
   "source": [
    "## c) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d9e35f",
   "metadata": {},
   "source": [
    "Schreiben Sie nun eine Funktion, die die Funktionen aus a) zu einem Netzwerk zusammenfügt. Die Inputs sind:\n",
    "\n",
    "- input_vector: 1D-Array mit den Inputs für das erste Layer.\n",
    "- weights: eine Liste mit k-Einträgen, wobei k die Anzahl hidden Layers ist. Jeder Eintrag enthält die Gewichtsmatrix für das entsprechende Layer.\n",
    "- biases: eine Liste mit k-Einträgen. Jeder Eintrag enthält den Biasvektor für das entsprechende Layer.\n",
    "\n",
    "Die Funktion iteriert durch alle Layers und propagiert immer den Output des vorigen Layers durch das nächste Layer. Verwenden Sie für alle Layers ausser dem allerletzten die ReLU-Aktivierungsfunktion. Für das letzte Layer verwenden Sie die Sigmoid-Aktivierungsfunktion.\n",
    "\n",
    "Für einen Classifier will man einen binären Output, 0 oder 1. Da die Sigmoid-Aktivierungsfunktion auch Werte zwischen 0 und 1 zurückgibt, müssen Sie diese noch mit `np.round` auf 0 oder 1 runden.\n",
    "\n",
    "*Bemerkung: Die Argumente `weights` und `biases` müssen python-Listen anstelle von Numpy-Arrays sein, da diese Einträge unterschiedlichen Typs haben können, z.B.:*\n",
    "```python\n",
    "liste = ['a', 2, np.array([2, 5])]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db021fd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45fd6c6a",
   "metadata": {},
   "source": [
    "## d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55de7846",
   "metadata": {},
   "source": [
    "Mit der Funktion in b) haben sie schon die `predict`-Funktion für einen NN-Classifier implementiert! Das Trainieren des Netzwerks, also das Optimieren der Gewichtsmatrizen und Biasvektoren, ist deutlich aufwendiger und übersteigt den Umfang dieser Übung.\n",
    "\n",
    "Allerdings können wir unsere Implementation auf Klassifizierungsprobleme anwenden, wenn wir das Resultat des Trainings, also die Gewichtsmatrizen und Biasvektoren, kennen.\n",
    "\n",
    "Der Datensatz `Data_3/data.csv` enthält ähnlich zu Aufgabe 2 zwei Spalten, die den x- und y-Koordinaten von Punkten entsprechen. Die Punkte können in einen inneren Kreis und einen äusseren Ring aufgeteilt werden.\n",
    "\n",
    "Laden Sie den Datensatz in eine Dataframe und plotten Sie die Punkte auf einem Scatterplot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98efdbac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a80a417",
   "metadata": {},
   "source": [
    "## e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2251b0",
   "metadata": {},
   "source": [
    "Benutzen Sie nun Ihre Funktion mit den bereitgestellten Gewichtsmatrizen und Biasvektoren, um für jeden Punkt eine Vorhersage zu treffen, ob er in der inneren oder der äusseren Menge liegt. \n",
    "\n",
    "Analog zur Spirale können Sie das Resultat in einem Scatterplot darstellen und die Vorhersage als Farbwert übergeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc1f6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = pickle.load(open('Data_3/weights.p', 'rb'))\n",
    "biases = pickle.load(open('Data_3/biases.p', 'rb'))\n",
    "\n",
    "# Ihr Code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "460.8px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
